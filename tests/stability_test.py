"""
ç©©å®šæ€§æ¸¬è©¦è…³æœ¬
é©—è­‰ RAG ç³»çµ±çš„æª¢ç´¢çµæœæ˜¯å¦ç©©å®šï¼ˆdeterministicï¼‰
"""
import asyncio
import json
from pathlib import Path
from typing import List, Dict
import sys
import os

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from vectorstore import vector_store
from retriever import search_similar_chunks
from ingest import split_text, get_embedding
from utils.debug_logger import rag_debug_logger, DEBUG_DIR


class StabilityTester:
    """ç©©å®šæ€§æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.test_results: List[Dict] = []
    
    async def test_embedding_consistency(self, text: str, iterations: int = 5) -> Dict:
        """
        æ¸¬è©¦ embedding ä¸€è‡´æ€§
        
        Args:
            text: æ¸¬è©¦æ–‡æœ¬
            iterations: æ¸¬è©¦æ¬¡æ•¸
        
        Returns:
            æ¸¬è©¦çµæœ
        """
        print(f"\nğŸ” æ¸¬è©¦ Embedding ä¸€è‡´æ€§...")
        print(f"   æ–‡æœ¬: {text[:50]}...")
        print(f"   æ¸¬è©¦æ¬¡æ•¸: {iterations}")
        
        embeddings = []
        for i in range(iterations):
            emb = await get_embedding(text)
            embeddings.append(emb)
            print(f"   ç¬¬ {i+1} æ¬¡: embedding ç¶­åº¦ = {len(emb)}")
        
        # æª¢æŸ¥ä¸€è‡´æ€§
        first_emb = embeddings[0]
        all_same = all(
            len(emb) == len(first_emb) and
            all(abs(a - b) < 1e-6 for a, b in zip(emb, first_emb))
            for emb in embeddings[1:]
        )
        
        result = {
            "test_name": "embedding_consistency",
            "text": text,
            "iterations": iterations,
            "all_embeddings_same": all_same,
            "embedding_dim": len(first_emb),
            "status": "âœ… PASS" if all_same else "âŒ FAIL"
        }
        
        print(f"   çµæœ: {result['status']}")
        return result
    
    async def test_retrieval_consistency(
        self,
        query: str,
        iterations: int = 5,
        top_k: int = 5
    ) -> Dict:
        """
        æ¸¬è©¦æª¢ç´¢ä¸€è‡´æ€§
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            iterations: æ¸¬è©¦æ¬¡æ•¸
            top_k: top-k åƒæ•¸
        
        Returns:
            æ¸¬è©¦çµæœ
        """
        print(f"\nğŸ” æ¸¬è©¦ Retrieval ä¸€è‡´æ€§...")
        print(f"   æŸ¥è©¢: {query}")
        print(f"   æ¸¬è©¦æ¬¡æ•¸: {iterations}, top_k: {top_k}")
        
        all_results = []
        for i in range(iterations):
            results = await search_similar_chunks(query, top_k)
            all_results.append(results)
            
            # è¨˜éŒ„æ¯æ¬¡æª¢ç´¢
            rag_debug_logger.log_retrieval(query, retrieved_chunks=results, top_k=top_k)
            
            print(f"   ç¬¬ {i+1} æ¬¡: æª¢ç´¢åˆ° {len(results)} å€‹ç‰‡æ®µ")
            if results:
                scores = [r.get("score", 0) for r in results]
                print(f"           ç›¸ä¼¼åº¦åˆ†æ•¸: {[round(s, 3) for s in scores]}")
        
        # æª¢æŸ¥ä¸€è‡´æ€§
        first_results = all_results[0]
        consistent = True
        differences = []
        
        for i, results in enumerate(all_results[1:], 1):
            if len(results) != len(first_results):
                consistent = False
                differences.append(f"ç¬¬ {i+1} æ¬¡çµæœæ•¸é‡ä¸åŒ: {len(results)} vs {len(first_results)}")
                continue
            
            # æª¢æŸ¥æ¯å€‹ä½ç½®çš„ chunk ID å’Œåˆ†æ•¸
            for j, (first, current) in enumerate(zip(first_results, results)):
                if first.get("id") != current.get("id"):
                    consistent = False
                    differences.append(
                        f"ç¬¬ {i+1} æ¬¡ rank {j+1} chunk ID ä¸åŒ: "
                        f"{first.get('id')} vs {current.get('id')}"
                    )
                
                score_diff = abs(first.get("score", 0) - current.get("score", 0))
                if score_diff > 1e-6:
                    consistent = False
                    differences.append(
                        f"ç¬¬ {i+1} æ¬¡ rank {j+1} åˆ†æ•¸ä¸åŒ: "
                        f"{first.get('score', 0):.6f} vs {current.get('score', 0):.6f}"
                    )
        
        result = {
            "test_name": "retrieval_consistency",
            "query": query,
            "iterations": iterations,
            "top_k": top_k,
            "is_consistent": consistent,
            "differences": differences,
            "status": "âœ… PASS" if consistent else "âŒ FAIL"
        }
        
        print(f"   çµæœ: {result['status']}")
        if differences:
            print(f"   å·®ç•°: {differences[:3]}...")  # åªé¡¯ç¤ºå‰3å€‹
        
        return result
    
    async def test_chunking_consistency(self, text: str, iterations: int = 5) -> Dict:
        """
        æ¸¬è©¦ chunking ä¸€è‡´æ€§
        
        Args:
            text: æ¸¬è©¦æ–‡æœ¬
            iterations: æ¸¬è©¦æ¬¡æ•¸
        
        Returns:
            æ¸¬è©¦çµæœ
        """
        print(f"\nğŸ” æ¸¬è©¦ Chunking ä¸€è‡´æ€§...")
        print(f"   æ–‡æœ¬é•·åº¦: {len(text)} å­—")
        print(f"   æ¸¬è©¦æ¬¡æ•¸: {iterations}")
        
        all_chunks = []
        for i in range(iterations):
            chunks = split_text(text)
            all_chunks.append(chunks)
            print(f"   ç¬¬ {i+1} æ¬¡: ç”¢ç”Ÿ {len(chunks)} å€‹ chunks")
        
        # æª¢æŸ¥ä¸€è‡´æ€§
        first_chunks = all_chunks[0]
        consistent = True
        differences = []
        
        for i, chunks in enumerate(all_chunks[1:], 1):
            if len(chunks) != len(first_chunks):
                consistent = False
                differences.append(f"ç¬¬ {i+1} æ¬¡ chunk æ•¸é‡ä¸åŒ: {len(chunks)} vs {len(first_chunks)}")
                continue
            
            for j, (first, current) in enumerate(zip(first_chunks, chunks)):
                if first != current:
                    consistent = False
                    differences.append(f"ç¬¬ {i+1} æ¬¡ chunk {j+1} å…§å®¹ä¸åŒ")
                    break
        
        result = {
            "test_name": "chunking_consistency",
            "text_length": len(text),
            "iterations": iterations,
            "chunks_count": len(first_chunks),
            "is_consistent": consistent,
            "differences": differences,
            "status": "âœ… PASS" if consistent else "âŒ FAIL"
        }
        
        print(f"   çµæœ: {result['status']}")
        return result
    
    async def run_all_tests(
        self,
        test_text: str,
        test_query: str,
        iterations: int = 5
    ):
        """
        åŸ·è¡Œæ‰€æœ‰ç©©å®šæ€§æ¸¬è©¦
        
        Args:
            test_text: æ¸¬è©¦æ–‡æœ¬
            test_query: æ¸¬è©¦æŸ¥è©¢
            iterations: æ¯å€‹æ¸¬è©¦çš„è¿­ä»£æ¬¡æ•¸
        """
        print("=" * 60)
        print("ğŸš€ RAG ç³»çµ±ç©©å®šæ€§æ¸¬è©¦")
        print("=" * 60)
        
        # ç¢ºä¿æœ‰æ–‡æª”åœ¨å‘é‡è³‡æ–™åº«ä¸­
        if vector_store.count_chunks() == 0:
            print("\nâš ï¸  å‘é‡è³‡æ–™åº«ç‚ºç©ºï¼Œå…ˆæ·»åŠ æ¸¬è©¦æ–‡æª”...")
            chunks = split_text(test_text)
            embeddings = []
            for chunk in chunks:
                emb = await get_embedding(chunk)
                embeddings.append(emb)
            
            vector_store.add_document(
                doc_id="test_doc_001",
                title="ç©©å®šæ€§æ¸¬è©¦æ–‡æª”",
                content=test_text,
                chunks=chunks,
                embeddings=embeddings
            )
            print(f"âœ… å·²æ·»åŠ æ¸¬è©¦æ–‡æª”: {len(chunks)} å€‹ chunks")
        
        # åŸ·è¡Œæ¸¬è©¦
        results = []
        
        # 1. Embedding ä¸€è‡´æ€§
        results.append(await self.test_embedding_consistency(test_text, iterations))
        
        # 2. Chunking ä¸€è‡´æ€§
        results.append(await self.test_chunking_consistency(test_text, iterations))
        
        # 3. Retrieval ä¸€è‡´æ€§
        results.append(await self.test_retrieval_consistency(test_query, iterations))
        
        # ä¿å­˜çµæœ
        self.test_results = results
        self.save_results()
        
        # é¡¯ç¤ºæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æ¸¬è©¦æ‘˜è¦")
        print("=" * 60)
        for result in results:
            print(f"{result['status']} {result['test_name']}")
        
        all_passed = all(r['status'] == 'âœ… PASS' for r in results)
        print(f"\n{'âœ… æ‰€æœ‰æ¸¬è©¦é€šé' if all_passed else 'âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—'}")
        
        return results
    
    def save_results(self):
        """ä¿å­˜æ¸¬è©¦çµæœ"""
        results_file = DEBUG_DIR / f"stability_test_{Path(__file__).stem}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                "test_results": self.test_results,
                "summary": {
                    "total_tests": len(self.test_results),
                    "passed": sum(1 for r in self.test_results if r['status'] == 'âœ… PASS'),
                    "failed": sum(1 for r in self.test_results if r['status'] == 'âŒ FAIL')
                }
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜: {results_file}")


async def main():
    """ä¸»å‡½æ•¸"""
    tester = StabilityTester()
    
    # æ¸¬è©¦æ•¸æ“š
    test_text = """
    äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è¨ˆç®—æ©Ÿç§‘å­¸çš„ä¸€å€‹åˆ†æ”¯ï¼Œè‡´åŠ›æ–¼å‰µå»ºèƒ½å¤ åŸ·è¡Œé€šå¸¸éœ€è¦äººé¡æ™ºèƒ½çš„ä»»å‹™çš„ç³»çµ±ã€‚
    AI ç³»çµ±å¯ä»¥å­¸ç¿’ã€æ¨ç†ã€æ„ŸçŸ¥ç’°å¢ƒä¸¦åšå‡ºæ±ºç­–ã€‚æ©Ÿå™¨å­¸ç¿’æ˜¯ AI çš„ä¸€å€‹å­é ˜åŸŸï¼Œå®ƒä½¿è¨ˆç®—æ©Ÿèƒ½å¤ å¾æ•¸æ“šä¸­å­¸ç¿’ï¼Œè€Œç„¡éœ€æ˜ç¢ºç·¨ç¨‹ã€‚
    æ·±åº¦å­¸ç¿’æ˜¯æ©Ÿå™¨å­¸ç¿’çš„ä¸€å€‹å­é›†ï¼Œä½¿ç”¨ç¥ç¶“ç¶²çµ¡ä¾†æ¨¡æ“¬äººè…¦çš„å·¥ä½œæ–¹å¼ã€‚
    RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰æ˜¯ä¸€ç¨®çµåˆæª¢ç´¢å’Œç”Ÿæˆçš„æŠ€è¡“ï¼Œç”¨æ–¼æé«˜èªè¨€æ¨¡å‹çš„æº–ç¢ºæ€§å’Œç›¸é—œæ€§ã€‚
    """
    
    test_query = "ä»€éº¼æ˜¯ RAGï¼Ÿ"
    
    await tester.run_all_tests(test_text, test_query, iterations=5)


if __name__ == "__main__":
    asyncio.run(main())


