# RAG å°ˆæ¡ˆ - PPT ä»£ç¢¼ç‰‡æ®µ

## ğŸ“‹ ç›®éŒ„

1. [æ¶æ§‹åœ–ä»£ç¢¼](#æ¶æ§‹åœ–ä»£ç¢¼)
2. [æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ](#æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ)
3. [ç©©å®šæ€§æ¸¬è©¦ä»£ç¢¼](#ç©©å®šæ€§æ¸¬è©¦ä»£ç¢¼)
4. [Debug Logging ä»£ç¢¼](#debug-logging-ä»£ç¢¼)

---

## ğŸ—ï¸ æ¶æ§‹åœ–ä»£ç¢¼

### åˆ†å±¤æ¶æ§‹ç¤ºæ„

```python
# åˆ†å±¤æ¶æ§‹ï¼šè·è²¬åˆ†é›¢
ingest/              # è³‡æ–™æ”å–å±¤
  â”œâ”€â”€ splitter.py   # æ–‡æœ¬åˆ‡å‰²
  â””â”€â”€ embedder.py   # å‘é‡åµŒå…¥

vectorstore/         # å‘é‡å­˜å„²å±¤
  â””â”€â”€ store.py      # å‘é‡è³‡æ–™åº«

retriever/           # æª¢ç´¢å±¤
  â””â”€â”€ search.py     # ç›¸ä¼¼åº¦æœå°‹

llm/                 # ç”Ÿæˆå±¤
  â”œâ”€â”€ qa.py         # RAG å•ç­”
  â””â”€â”€ summarizer.py # æ‘˜è¦ç”Ÿæˆ

routes/              # API è·¯ç”±å±¤
  â”œâ”€â”€ documents.py   # æ–‡æª”ç®¡ç†
  â””â”€â”€ rag.py        # RAG å•ç­”
```

---

## ğŸ’» æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ

### 1. ä¸»å…¥å£ï¼ˆç°¡æ½”æ¸…æ™°ï¼‰

```python
# main.py - åªæœ‰ 125 è¡Œ
from fastapi import FastAPI
from routes import documents_router, rag_router

app = FastAPI(title="RAG æ‘˜è¦èˆ‡QA API")

# è¨»å†Šè·¯ç”±
app.include_router(documents_router)
app.include_router(rag_router)
```

**èªªæ˜**ï¼šå¾ 800+ è¡Œé‡æ§‹ç‚ºåˆ†å±¤æ¶æ§‹ï¼Œä¸»æ–‡ä»¶åªæœ‰ 125 è¡Œ

---

### 2. æ–‡æœ¬åˆ‡å‰²ï¼ˆå¯é…ç½®ï¼‰

```python
# ingest/splitter.py
def split_text(
    text: str, 
    chunk_size: int = CHUNK_SIZE,  # å¯é…ç½®
    overlap: int = CHUNK_OVERLAP   # å¯é…ç½®
) -> List[str]:
    """
    å°‡æ–‡æœ¬åˆ†å‰²æˆå°å¡Š
    æ”¯æŒå‹•æ…‹èª¿æ•´ chunk size å’Œ overlap
    """
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = re.split(r'\n\s*\n', text)
    
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) <= chunk_size:
            current_chunk += para
        else:
            chunks.append(current_chunk)
            # è™•ç† overlap
            current_chunk = para[-overlap:] + para
    
    return chunks
```

**èªªæ˜**ï¼šå¯é…ç½®çš„ chunking strategyï¼Œæ”¯æŒèª¿æ•´åƒæ•¸

---

### 3. Cosine Similarityï¼ˆèªæ„ç›¸ä¼¼åº¦ï¼‰

```python
# vectorstore/store.py
def _cosine_similarity(
    self, 
    a: List[float], 
    b: List[float]
) -> float:
    """
    è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
    æ¯”æ­æ°è·é›¢æ›´é©åˆé«˜ç¶­å‘é‡
    """
    dot_product = sum(x * y for x, y in zip(a, b))
    norm_a = math.sqrt(sum(x * x for x in a))
    norm_b = math.sqrt(sum(x * x for x in b))
    
    if norm_a == 0 or norm_b == 0:
        return 0.0
    
    return dot_product / (norm_a * norm_b)
```

**èªªæ˜**ï¼šä½¿ç”¨ cosine similarity è¨ˆç®—èªæ„ç›¸ä¼¼åº¦

---

### 4. Top-K Retrievalï¼ˆæª¢ç´¢æœ€ç›¸é—œå…§å®¹ï¼‰

```python
# vectorstore/store.py
def search(
    self, 
    query_embedding: List[float], 
    top_k: int = 5
) -> List[dict]:
    """
    å‘é‡ç›¸ä¼¼åº¦æœç´¢
    è¿”å›æœ€ç›¸é—œçš„ k å€‹çµæœ
    """
    # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
    scores = []
    for i, emb in enumerate(self.embeddings):
        score = self._cosine_similarity(query_embedding, emb)
        scores.append((i, score))
    
    # æ’åºä¸¦è¿”å› top_k
    scores.sort(key=lambda x: x[1], reverse=True)
    
    results = []
    for i, score in scores[:top_k]:
        chunk = self.chunks[i].copy()
        chunk["score"] = score  # é™„å¸¶ç›¸ä¼¼åº¦åˆ†æ•¸
        results.append(chunk)
    
    return results
```

**èªªæ˜**ï¼šTop-k retrieval ç¢ºä¿åªè¿”å›æœ€ç›¸é—œçš„å…§å®¹

---

### 5. RAG å•ç­”ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```python
# llm/qa.py
async def rag_qa(
    question: str, 
    context_chunks: List[Dict], 
    language: str = "zh-TW"
) -> tuple[str, str]:
    """
    RAG å•ç­”æµç¨‹ï¼š
    1. çµ„åˆä¸Šä¸‹æ–‡
    2. æ§‹å»º prompt
    3. èª¿ç”¨ LLM
    4. è¨ˆç®—ä¿¡å¿ƒç¨‹åº¦
    """
    # çµ„åˆä¸Šä¸‹æ–‡
    context = "\n\n---\n\n".join([
        f"[ä¾†æº: {chunk['title']}]\n{chunk['content']}"
        for chunk in context_chunks
    ])
    
    # æ§‹å»º prompt
    prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚

## åƒè€ƒè³‡æ–™
{context}

## å•é¡Œ
{question}"""
    
    # èª¿ç”¨ LLM
    answer = await call_ollama(prompt, system_prompt)
    
    # è¨ˆç®—ä¿¡å¿ƒç¨‹åº¦ï¼ˆåŸºæ–¼ç›¸ä¼¼åº¦åˆ†æ•¸ï¼‰
    avg_score = sum(chunk.get("score", 0) for chunk in context_chunks) / len(context_chunks)
    if avg_score > 0.7:
        confidence = "high"
    elif avg_score > 0.5:
        confidence = "medium"
    else:
        confidence = "low"
    
    return answer, confidence
```

**èªªæ˜**ï¼šå®Œæ•´çš„ RAG æµç¨‹ï¼ŒåŒ…å«ä¿¡å¿ƒç¨‹åº¦è¨ˆç®—

---

## ğŸ§ª ç©©å®šæ€§æ¸¬è©¦ä»£ç¢¼

### Embedding ä¸€è‡´æ€§æ¸¬è©¦

```python
# tests/stability_test.py
async def test_embedding_consistency(
    self, 
    text: str, 
    iterations: int = 5
) -> Dict:
    """
    æ¸¬è©¦ embedding ä¸€è‡´æ€§
    é©—è­‰åŒä¸€æ–‡æœ¬å¤šæ¬¡ç”Ÿæˆ embedding æ˜¯å¦ç›¸åŒ
    """
    embeddings = []
    for i in range(iterations):
        emb = await get_embedding(text)
        embeddings.append(emb)
    
    # æª¢æŸ¥ä¸€è‡´æ€§
    first_emb = embeddings[0]
    all_same = all(
        abs(a - b) < 1e-6 
        for a, b in zip(emb, first_emb)
        for emb in embeddings[1:]
    )
    
    return {
        "status": "âœ… PASS" if all_same else "âŒ FAIL",
        "all_embeddings_same": all_same
    }
```

**èªªæ˜**ï¼šé©—è­‰ embedding çš„ deterministic ç‰¹æ€§

---

### Retrieval ä¸€è‡´æ€§æ¸¬è©¦

```python
# tests/stability_test.py
async def test_retrieval_consistency(
    self,
    query: str,
    iterations: int = 5,
    top_k: int = 5
) -> Dict:
    """
    æ¸¬è©¦æª¢ç´¢ä¸€è‡´æ€§
    é©—è­‰åŒä¸€ query å¤šæ¬¡æª¢ç´¢çµæœæ˜¯å¦ç›¸åŒ
    """
    all_results = []
    for i in range(iterations):
        results = await search_similar_chunks(query, top_k)
        all_results.append(results)
    
    # æª¢æŸ¥ä¸€è‡´æ€§
    first_results = all_results[0]
    consistent = all(
        len(results) == len(first_results) and
        all(
            r.get("id") == first.get("id") and
            abs(r.get("score", 0) - first.get("score", 0)) < 1e-6
            for r, first in zip(results, first_results)
        )
        for results in all_results[1:]
    )
    
    return {
        "status": "âœ… PASS" if consistent else "âŒ FAIL",
        "is_consistent": consistent
    }
```

**èªªæ˜**ï¼šé©—è­‰æª¢ç´¢éç¨‹çš„ deterministic ç‰¹æ€§

---

## ğŸ” Debug Logging ä»£ç¢¼

### æª¢ç´¢éç¨‹è¨˜éŒ„

```python
# utils/debug_logger.py
def log_retrieval(
    self,
    query: str,
    retrieved_chunks: List[Dict],
    top_k: int = 5
):
    """
    è¨˜éŒ„æª¢ç´¢éç¨‹
    åŒ…å«ï¼šæŸ¥è©¢ã€æª¢ç´¢çµæœã€ç›¸ä¼¼åº¦åˆ†æ•¸
    """
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "type": "retrieval",
        "query": query,
        "top_k": top_k,
        "retrieved_count": len(retrieved_chunks),
        "chunks": [
            {
                "rank": i + 1,
                "document_title": chunk.get("title"),
                "similarity_score": round(chunk.get("score", 0), 4),
                "content_preview": chunk.get("content", "")[:100]
            }
            for i, chunk in enumerate(retrieved_chunks)
        ]
    }
    
    # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
    if retrieved_chunks:
        scores = [chunk.get("score", 0) for chunk in retrieved_chunks]
        log_entry["statistics"] = {
            "avg_score": sum(scores) / len(scores),
            "max_score": max(scores),
            "min_score": min(scores)
        }
    
    self.session_logs.append(log_entry)
```

**èªªæ˜**ï¼šè¨˜éŒ„æ¯æ¬¡æª¢ç´¢çš„è©³ç´°ä¿¡æ¯ï¼Œæ–¹ä¾¿ debug

---

### å®Œæ•´ RAG æœƒè©±è¨˜éŒ„

```python
# utils/debug_logger.py
def log_full_rag_session(
    self,
    question: str,
    retrieved_chunks: List[Dict],
    answer: str,
    confidence: str,
    top_k: int = 5
):
    """
    è¨˜éŒ„å®Œæ•´çš„ RAG æœƒè©±
    åŒ…å«ï¼šå•é¡Œã€æª¢ç´¢çµæœã€ç­”æ¡ˆã€ä¿¡å¿ƒç¨‹åº¦
    """
    session = {
        "timestamp": datetime.now().isoformat(),
        "type": "full_rag_session",
        "question": question,
        "top_k": top_k,
        "retrieved_chunks": [
            {
                "document_title": chunk.get("title"),
                "similarity_score": round(chunk.get("score", 0), 4),
                "content_preview": chunk.get("content", "")[:200]
            }
            for chunk in retrieved_chunks
        ],
        "answer": answer,
        "confidence": confidence,
        "answer_quality_indicators": {
            "avg_similarity": round(
                sum(chunk.get("score", 0) for chunk in retrieved_chunks) / len(retrieved_chunks),
                4
            ),
            "has_high_confidence_chunks": any(
                chunk.get("score", 0) > 0.7 for chunk in retrieved_chunks
            )
        }
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    session_file = DEBUG_DIR / f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(session_file, 'w', encoding='utf-8') as f:
        json.dump(session, f, ensure_ascii=False, indent=2)
```

**èªªæ˜**ï¼šè¨˜éŒ„å®Œæ•´çš„ RAG æœƒè©±ï¼Œæ–¹ä¾¿äº‹å¾Œåˆ†æ

---

## ğŸ“Š PPT ä½¿ç”¨å»ºè­°

### 1. æ¶æ§‹åœ–
- ä½¿ç”¨ç¬¬ä¸€éƒ¨åˆ†çš„æ¶æ§‹ç¤ºæ„ä»£ç¢¼
- å¯ä»¥é…åˆæµç¨‹åœ–èªªæ˜æ•¸æ“šæµå‘

### 2. æ ¸å¿ƒåŠŸèƒ½
- é¸æ“‡ 2-3 å€‹æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ
- é‡é»èªªæ˜è¨­è¨ˆæ±ºç­–ï¼ˆå¦‚ç‚ºä»€éº¼ç”¨ cosine similarityï¼‰

### 3. ç©©å®šæ€§èˆ‡ Debug
- å±•ç¤ºç©©å®šæ€§æ¸¬è©¦ä»£ç¢¼
- èªªæ˜å¦‚ä½•é€šé logging å¿«é€Ÿå®šä½å•é¡Œ

### 4. ä»£ç¢¼å±•ç¤ºæŠ€å·§
- åªå±•ç¤ºé—œéµéƒ¨åˆ†ï¼Œä¸è¦å…¨éƒ¨ä»£ç¢¼
- ç”¨è¨»é‡‹èªªæ˜é‡é»
- å¯ä»¥é…åˆæµç¨‹åœ–æˆ–æ¶æ§‹åœ–

---

## ğŸ¯ é‡é»å¼·èª¿

1. **åˆ†å±¤æ¶æ§‹**ï¼šå¾ 800+ è¡Œé‡æ§‹ç‚ºæ¸…æ™°çš„äº”å±¤æ¶æ§‹
2. **å¯é…ç½®æ€§**ï¼šchunk size å’Œ overlap å¯èª¿æ•´
3. **ç©©å®šæ€§**ï¼šå¯¦ä½œç©©å®šæ€§æ¸¬è©¦ç¢ºä¿ deterministic
4. **Debug èƒ½åŠ›**ï¼šå®Œæ•´çš„ logging ç³»çµ±æ–¹ä¾¿å•é¡Œå®šä½
5. **æŠ€è¡“é¸å‹**ï¼šcosine similarity + top-k retrieval

