"""
AI é æ¸¬æ¨¡å‹ä¸»å…¥å£
å±•ç¤ºåˆ†å±¤æ¶æ§‹è¨­è¨ˆ
"""
import numpy as np
from ai_predict import Predictor, DataPreprocessor, FeatureExtractor


def main():
    """ä¸»å‡½æ•¸ - å®Œæ•´çš„é æ¸¬æµç¨‹ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ¤– AI é æ¸¬æ¨¡å‹ - åˆ†å±¤æ¶æ§‹ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. ç”Ÿæˆç¤ºä¾‹æ•¸æ“š
    print("\nğŸ“Š æ­¥é©Ÿ 1: æº–å‚™æ•¸æ“š")
    np.random.seed(42)
    n_samples = 100
    n_features = 3
    
    # ç”Ÿæˆç‰¹å¾µæ•¸æ“šï¼ˆæ¨¡æ“¬çœŸå¯¦å ´æ™¯ï¼‰
    X_raw = np.random.randn(n_samples, n_features) * 10 + 50
    # ç”Ÿæˆç›®æ¨™å€¼ï¼ˆç·šæ€§é—œä¿‚ + å™ªéŸ³ï¼‰
    y = (X_raw[:, 0] * 2 + X_raw[:, 1] * 1.5 + X_raw[:, 2] * 0.5 + 
         np.random.randn(n_samples) * 5)
    
    print(f"åŸå§‹æ•¸æ“šå½¢ç‹€: X={X_raw.shape}, y={y.shape}")
    
    # 2. æ•¸æ“šé è™•ç†
    print("\nğŸ”§ æ­¥é©Ÿ 2: æ•¸æ“šé è™•ç†")
    preprocessor = DataPreprocessor(normalize=True)
    X_processed = preprocessor.fit_transform(X_raw)
    print(f"è™•ç†å¾Œæ•¸æ“šå½¢ç‹€: {X_processed.shape}")
    print(f"æ¨™æº–åŒ–çµ±è¨ˆ: mean={preprocessor.mean[:2]}, std={preprocessor.std[:2]}")
    
    # 3. ç‰¹å¾µæå–
    print("\nğŸ¯ æ­¥é©Ÿ 3: ç‰¹å¾µæå–")
    feature_extractor = FeatureExtractor()
    
    # æå–åŸºæœ¬ç‰¹å¾µ
    basic_features = feature_extractor.extract_basic_features(X_processed)
    print(f"åŸºæœ¬ç‰¹å¾µæ•¸é‡: {len(basic_features)}")
    
    # æå–æ™‚é–“åºåˆ—ç‰¹å¾µï¼ˆå¦‚æœé©ç”¨ï¼‰
    temporal_features = feature_extractor.extract_temporal_features(
        X_processed.flatten()[:20], window_size=3
    )
    print(f"æ™‚é–“åºåˆ—ç‰¹å¾µæ•¸é‡: {len(temporal_features)}")
    
    # çµ„åˆç‰¹å¾µ
    combined_features = feature_extractor.combine_features(
        basic_features, temporal_features
    )
    print(f"çµ„åˆå¾Œç‰¹å¾µæ•¸é‡: {len(combined_features)}")
    
    # 4. åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†
    print("\nğŸ“¦ æ­¥é©Ÿ 4: æ•¸æ“šåˆ†å‰²")
    split_idx = int(n_samples * 0.8)
    X_train, X_test = X_processed[:split_idx], X_processed[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    print(f"è¨“ç·´é›†: {X_train.shape[0]} æ¨£æœ¬")
    print(f"æ¸¬è©¦é›†: {X_test.shape[0]} æ¨£æœ¬")
    
    # 5. è¨“ç·´æ¨¡å‹
    print("\nğŸš€ æ­¥é©Ÿ 5: è¨“ç·´æ¨¡å‹")
    predictor = Predictor(model_type='random_forest')
    train_metrics = predictor.train(X_train, y_train)
    print(f"è¨“ç·´æŒ‡æ¨™: MSE={train_metrics['train_mse']:.2f}, "
          f"MAE={train_metrics['train_mae']:.2f}, "
          f"RÂ²={train_metrics['train_r2']:.3f}")
    
    # 6. æ¨¡å‹è©•ä¼°
    print("\nğŸ“ˆ æ­¥é©Ÿ 6: æ¨¡å‹è©•ä¼°")
    test_metrics = predictor.evaluate(X_test, y_test)
    print(f"æ¸¬è©¦æŒ‡æ¨™:")
    print(f"  - MSE (å‡æ–¹èª¤å·®): {test_metrics['mse']:.2f}")
    print(f"  - MAE (å¹³å‡çµ•å°èª¤å·®): {test_metrics['mae']:.2f}")
    print(f"  - RMSE (å‡æ–¹æ ¹èª¤å·®): {test_metrics['rmse']:.2f}")
    print(f"  - RÂ² (æ±ºå®šä¿‚æ•¸): {test_metrics['r2']:.3f}")
    
    # 7. ç‰¹å¾µé‡è¦æ€§
    print("\nğŸ” æ­¥é©Ÿ 7: ç‰¹å¾µé‡è¦æ€§åˆ†æ")
    feature_importance = predictor.get_feature_importance()
    if feature_importance is not None:
        print(f"ç‰¹å¾µé‡è¦æ€§: {feature_importance}")
        print(f"æœ€é‡è¦ç‰¹å¾µç´¢å¼•: {np.argmax(feature_importance)}")
    
    # 8. é€²è¡Œé æ¸¬
    print("\nğŸ¯ æ­¥é©Ÿ 8: é€²è¡Œé æ¸¬")
    sample_X = X_test[:5]
    predictions = predictor.predict(sample_X)
    actual = y_test[:5]
    
    print("é æ¸¬çµæœå°æ¯”:")
    for i, (pred, actual_val) in enumerate(zip(predictions, actual)):
        error = abs(pred - actual_val)
        print(f"  æ¨£æœ¬ {i+1}: é æ¸¬={pred:.2f}, å¯¦éš›={actual_val:.2f}, "
              f"èª¤å·®={error:.2f}")


if __name__ == "__main__":
    main()

